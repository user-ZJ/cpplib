# 多线程

## c++11多线程

```cpp
#include <iostream>
#include <thread>
std::thread::id main_thread_id = std::this_thread::get_id();
void hello()  
{
    std::cout << "Hello Concurrent World\n";
    if (main_thread_id == std::this_thread::get_id())
        std::cout << "This is the main thread.\n";
    else
        std::cout << "This is not the main thread.\n";
}
void pause_thread(int n) {
    std::this_thread::sleep_for(std::chrono::seconds(n));
    std::cout << "pause of " << n << " seconds ended\n";
}
int main() {
    std::thread t(hello);
    std::cout << t.hardware_concurrency() << std::endl;//可以并发执行多少个(不准确)
    std::cout << "native_handle " << t.native_handle() << std::endl;//可以并发执行多少个(不准确)
    t.join();
    std::thread a(hello);
    a.detach();
    std::thread threads[5];                         // 默认构造线程

    std::cout << "Spawning 5 threads...\n";
    for (int i = 0; i < 5; ++i)
        threads[i] = std::thread(pause_thread, i + 1);   // move-assign threads
    std::cout << "Done spawning threads. Now waiting for them to join:\n";
    for (auto &thread : threads)
        thread.join();
    std::cout << "All threads joined!\n";
}
```

```
g++ -std=c++11 test.cpp -lpthread
```

## omp

使用omp来使用多线程。它的好处是跨平台，使用简单。

在Linux平台上，如果需要使用omp，只需在编译时使用"-fopenmp"指令。在Windows的visual studio开发环境中，开启omp支持的步骤为“项目属性 -> C/C++ -> 所有选项 -> openmp支持 -> 是(/openmp)”。

openmp是由一系列#paragma指令组成，这些指令控制如何多线程的执行程序。另外，即使编译器不支持omp，程序也也能够正常运行，只是程序不会多线程并行运行

所有的omp指令都是以"#pragma omp“开头，换行符结束。并且除了barrier和flush两个指令不作用于代码以外，其他的指令都只与指令后面的那段代码相关

```cpp
#include <iostream>
#include <vector>

using namespace std;

int main()
{
 #pragma omp parallel for
    for (int i = 0; i < 10; ++i)                                                                                                                                                                            
    {   
       printf("%d ", i); 
    }   
    return 0;
}
```

```shell
g++ -std=c++11 -fopenmp omp.cc
```

### omp语法

* parallel 

parallel告诉编译器开始 一个并行块，编译器会创建一个包含N（在运行时决定，通常为硬件线程数）个线程的线程组，所有线程都运行接下来的语句或者由”{...}"包含的代码块，在这执行结束之后，又回到主线程，创建的这N个线程会被回收

GCC编译器的实现方式是在内部创建一个函数，然后将相关的执行代码移至这个函数，这样一来代码块中定义的变量成为了线程的局部变量，互不影响

parallel指令所创建的线程组的线程数默认是有编译器决定的，我们也可以通过num_threads指令来指定线程数，如”#pragma omp parallel num_threads(3)“即告诉编译器，此处需要创建一个包含3个线程的线程组

* for

omp中的for指令用于告诉编译器，拆分接下来的for循环，并分别在不同的线程中运行不同的部分。如果for指令后没有紧接着for循环，编译器会报错

```cpp
#pragma omp parallel  
 {
#pragma  omp for
  for (int i = 0; i < 10; ++i)
  {
   printf("%d ", i);
  }
//如果此处没有#pragma omp parallel指令，那么for循环只会在主线程中执行
```

* Schedule

Schedule指令提供对for指令中线程调度更多的控制能力。它有两种调度方式：static和dynamic

**static**：每个线程自行决定要执行哪个块，即每个线程执行for循环中的一个子块。

**dynamic**：一个线程并不是执行for循环的一个子块，而是每次都向omp运行时库索取一个for循环中的迭代值，然后执行这次迭代，在执行完之后再索取新的值。因此，线程有可能执行任意的迭代值，而不是一个子块。

”#pragma omp parallel for“实际上的效果是”#pragma omp parallel for schedule(static)"。如果我们将之前的示例采用dynamic调度方式，即”#pragma omp parallel for schedule(dynamic)"

在dynamic调度方式中，还可以指定每次索取的迭代值数量,如：“#pragma omp parallel  for schedule(dynamic，3)”

每个线程每次都索取3个迭代值。执行完之后，再拿3个迭代值，直到for循环所有迭代值都运行结束。在最后一次索取的结果有可能不足3个。

* ordered

ordered指令用于控制一段代码在for循环中的执行顺序，它保证这段代码一定是按照for中的顺序依次执行的

```cpp
#pragma  omp parallel for ordered schedule(dynamic)
for (int i = 0; i < 10; ++i)
{
    Data data = ReadFile(files[i]);
#pragma omp ordered
    PutDataToDataset(data);
}
```

这个循环负责读取10个文件，然后将数据放入一个内存结构中。读文件的操作是并行的，但是将数据存入内存结构中则是严格串行的。即先存第一个文件数据，然后第二个...，最后是第十个文件。假设一个线程已经读取了第七个文件的，但是第六个文件还没有存入内存结构，那么这个线程会阻塞，知道第六个文件存入内存结构之后，线程才会继续运行。

在每一个ordered for循环中，有且仅有一个“#pragma omp ordered"指令限定的代码块。

* section

section指令用于指定哪些程序块可以并行运行。一个section块内的代码必须串行运行，而section块之间是可以并行运行的。

* task

当觉得for和section指令用着不方便时，可以用task指令。它用于告诉编译器其后续的指令可以并行运行

* atomic

atomic指令用于保证其后续的语句执行时原子性的。所谓原子性，即事务的概念，它的执行不可拆分，要么执行成功，要么什么都没有执行

atomic只能用于简单的表达式，比如+=、-=、*=、&=等，它们通常能够被编译成一条指令。

* critical

critical指令用于保证其相关联的代码只在一个线程中执行。另外，我们还可以给critical指令传递一个名称，这个名称是全局性的，所有具有相同名字的critical相关联的代码保证不会同时在多个线程中运行，同一时间最多只会有一个代码块在运行。如果没有指定名称，那系统会给定一个默认的名称

* 锁

omp运行库提供了一种锁：omp_lock_t，它定义在omp.h头文件中。针对omp_lock_t有5中操作，它们分别是：

`omp_init_lock` 初始化锁，初始化后锁处于未锁定状态.

`omp_destroy_lock` 销毁锁，调用这个函数时，锁必须是未锁定状态.

`omp_set_lock` 尝试获取锁，如果锁已经被其他线程加锁了，那当前线程进入阻塞状态。

`omp_unset_lock` 释放锁，调用这个方法的线程必须已经获得了锁，如果当前线程没有获得锁，则会有未定义行为。

`omp_test_lock` a尝试获取锁，获取锁成功则返回1，否则返回0.

omp_lock_t相当于mutex,如果线程已经获得了锁，那在释放锁之前，当前线程不能对锁进行上锁。为了满足这种递归锁的需求，omp提供了omp_nest_lock_t，这种锁相当于recursive_mutex可以递归上锁，但是释放操作必须与上锁操作一一对应，否则锁不会得到释放。

* flush

多线程之间共享变量

private`, `firstprivate,lastprivate` 及 `shared指令控制变量共享方式

其中private,firstprivate,lastprivate表示变量的共享方式是私有的，即每个线程都有一份自己的拷贝；而shared表示线程组的线程访问的是同一个变量

* default

default命令用于设置所有变量的默认的共享方式，如default(shared)表示所有变量默认共享方式为shared

使用default(none)来检查我们是否显示设置了所有使用了的变量的共享方式

default中的参数不能使用private、firstprivate以及lastprivate。

```cpp
int a, b=0;
#pragma omp parallel default(none) shared(b)
{
   b += a;
}
//以上代码无法通过编译，因为在parallel的代码块中使用了变量a和b，但是我们只设置了b的共享方式，而没有设置变量a的共享方式
```

* reduction

reductino指令是private,shared及atomic的综合体。它的语法是：

  reduction(operator : list)

其中operator指操作符，list表示操作符要作用的列表，通常是一个共享变量名，之所以称之为列表是因为线程组中的每个线程都有一份变量的拷贝，reduction即负责用给定的操作符将这些拷贝的局部变量的值进行聚合，并设置回共享变量。

**Operator**可以是：+`, `-`, `|`, `^`, `||,*`, `&&,&

```cpp
//阶乘的多线程的实现
int factorial(int number)
{
int fac =1;
#pragma omp parallel for reduction(*:fac)
for(int n=2; n<=number;++n)
     fac *= n;
return fac;
}

//不用reduction，那么则需用适用atomic指令,但是这样一来，性能会大大的下降，因为这里没有使用局部变量，每个线程对fac的操作都需要进行同步。所以在这个例子中，并不会从多线程中受益多少，因为atomic成为了性能瓶颈。
int factorial(int number)
{
int fac =1;
#pragma omp parallel for
for(int n=2; n<=number;++n)
{
#pragma omp atomic
     fac *= n;
}
return fac;
}

//使用reduction指令的代码事实上类似于以下代码
int factorial(int number)
{
int fac =1;
#pragma omp parallel
{
int fac_private =1;
#pragma omp for nowait
for(int n=2; n<=number;++n)
       fac_private *= n;
#pragma omp atomic
     fac *= fac_private;
}
return fac;
}
```

* barrier

barrier指令是线程组中线程的一个同步点，只有线程组中的所有线程都到达这个位置之后，才会继续往下运行。而在每个for、section以及后面要讲到的single代码块最后都隐式的设置了barrier指令。

* nowait

nowait指令用来告诉编译器无需隐式调用barrier指令，因此如果为for、section、single设置了nowait标志，则在它们最后不会隐式的调用barrier指令

* single

single指令相关的代码块只运行一个线程执行，但并不限定具体哪一个线程来执行，其它线程必须跳过这个代码块，并在代码块后wait，直到执行这段代码的线程完成。

```cpp
#pragma omp parallel
{
   Work1();
#pragma omp single
{
     Work2();
}
   Work3();
}
//work1()和work3()会在线程组中所有线程都 运行一遍，但是work2()只会在一个线程中执行，即只会执行一遍。
```

* master

master指令则指定其相关的代码块必须在主线程中执行，且其它线程不必在代码块后阻塞



### reference

https://blog.csdn.net/acaiwlj/article/details/49818965